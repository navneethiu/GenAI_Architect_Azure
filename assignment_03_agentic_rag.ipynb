{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzoo06S5CNRXvAz2es7odh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BhanuPrakashSamoju/gen_ai_architect_program/blob/main/assignments/assignment_03/assignment_03_agentic_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "k-07cmG3zzes",
        "outputId": "dad96821-14f0-4013-9c20-247e2759ed03"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.3.27 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 2)) (0.3.27)\n",
            "Collecting langgraph==0.6.7 (from -r /content/requirements.txt (line 3))\n",
            "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain-openai==0.3.33 (from -r /content/requirements.txt (line 4))\n",
            "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-community==0.3.29 (from -r /content/requirements.txt (line 5))\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pydantic==2.11.7 (from -r /content/requirements.txt (line 6))\n",
            "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain_google_genai (from -r /content/requirements.txt (line 7))\n",
            "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting pinecone (from -r /content/requirements.txt (line 12))\n",
            "  Downloading pinecone-7.3.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting azure-identity (from -r /content/requirements.txt (line 15))\n",
            "  Downloading azure_identity-1.25.0-py3-none-any.whl.metadata (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-ai-inference (from -r /content/requirements.txt (line 16))\n",
            "  Downloading azure_ai_inference-1.0.0b9-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting mlflow (from -r /content/requirements.txt (line 19))\n",
            "  Downloading mlflow-3.4.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 22)) (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 23)) (2.32.4)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 26)) (1.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 28)) (4.67.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27->-r /content/requirements.txt (line 2)) (0.3.77)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27->-r /content/requirements.txt (line 2)) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27->-r /content/requirements.txt (line 2)) (0.4.31)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27->-r /content/requirements.txt (line 2)) (2.0.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27->-r /content/requirements.txt (line 2)) (6.0.3)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph==0.6.7->-r /content/requirements.txt (line 3))\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph==0.6.7->-r /content/requirements.txt (line 3))\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph==0.6.7->-r /content/requirements.txt (line 3))\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph==0.6.7->-r /content/requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.33->-r /content/requirements.txt (line 4)) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.3.33->-r /content/requirements.txt (line 4)) (0.11.0)\n",
            "Collecting requests (from -r /content/requirements.txt (line 23))\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.29->-r /content/requirements.txt (line 5)) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.29->-r /content/requirements.txt (line 5)) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community==0.3.29->-r /content/requirements.txt (line 5))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.29->-r /content/requirements.txt (line 5)) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.29->-r /content/requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.29->-r /content/requirements.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.7->-r /content/requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.7->-r /content/requirements.txt (line 6)) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.7->-r /content/requirements.txt (line 6)) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.7->-r /content/requirements.txt (line 6)) (0.4.2)\n",
            "Collecting google-ai-generativelanguage<1,>=0.7 (from langchain_google_genai->-r /content/requirements.txt (line 7))\n",
            "  Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting filetype<2,>=1.2 (from langchain_google_genai->-r /content/requirements.txt (line 7))\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.12/dist-packages (from pinecone->-r /content/requirements.txt (line 12)) (2025.8.3)\n",
            "Collecting pinecone-plugin-assistant<2.0.0,>=1.6.0 (from pinecone->-r /content/requirements.txt (line 12))\n",
            "  Downloading pinecone_plugin_assistant-1.8.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone->-r /content/requirements.txt (line 12))\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone->-r /content/requirements.txt (line 12)) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone->-r /content/requirements.txt (line 12)) (2.5.0)\n",
            "Collecting azure-core>=1.31.0 (from azure-identity->-r /content/requirements.txt (line 15))\n",
            "  Downloading azure_core-1.35.1-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.12/dist-packages (from azure-identity->-r /content/requirements.txt (line 15)) (43.0.3)\n",
            "Collecting msal>=1.30.0 (from azure-identity->-r /content/requirements.txt (line 15))\n",
            "  Downloading msal-1.34.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting msal-extensions>=1.2.0 (from azure-identity->-r /content/requirements.txt (line 15))\n",
            "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting isodate>=0.6.1 (from azure-ai-inference->-r /content/requirements.txt (line 16))\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mlflow-skinny==3.4.0 (from mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading mlflow_skinny-3.4.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-tracing==3.4.0 (from mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading mlflow_tracing-3.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow->-r /content/requirements.txt (line 19)) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow->-r /content/requirements.txt (line 19)) (1.16.5)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fastmcp<3,>=2.0.0 (from mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading fastmcp-2.12.4-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting graphene<4 (from mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow->-r /content/requirements.txt (line 19)) (3.10.0)\n",
            "Requirement already satisfied: pyarrow<22,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow->-r /content/requirements.txt (line 19)) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow->-r /content/requirements.txt (line 19)) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow->-r /content/requirements.txt (line 19)) (1.16.2)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (8.3.0)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading databricks_sdk-0.67.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (0.118.0)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (1.37.0)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (5.29.5)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (0.5.3)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (0.37.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/requirements.txt (line 22)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/requirements.txt (line 22)) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->-r /content/requirements.txt (line 23)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->-r /content/requirements.txt (line 23)) (3.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.29->-r /content/requirements.txt (line 5)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.29->-r /content/requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.29->-r /content/requirements.txt (line 5)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.29->-r /content/requirements.txt (line 5)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.29->-r /content/requirements.txt (line 5)) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.29->-r /content/requirements.txt (line 5)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.29->-r /content/requirements.txt (line 5)) (1.20.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow->-r /content/requirements.txt (line 19)) (1.3.10)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from azure-core>=1.31.0->azure-identity->-r /content/requirements.txt (line 15)) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=2.5->azure-identity->-r /content/requirements.txt (line 15)) (2.0.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community==0.3.29->-r /content/requirements.txt (line 5))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community==0.3.29->-r /content/requirements.txt (line 5))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: authlib>=1.5.2 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (1.6.4)\n",
            "Collecting cyclopts>=3.0.0 (from fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading cyclopts-3.24.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting exceptiongroup>=1.2.2 (from fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (0.28.1)\n",
            "Requirement already satisfied: mcp<2.0.0,>=1.12.4 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (1.15.0)\n",
            "Collecting openapi-core>=0.19.5 (from fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading openapi_core-0.19.5-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting openapi-pydantic>=0.5.1 (from fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading openapi_pydantic-0.5.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pyperclip>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (1.11.0)\n",
            "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (13.9.4)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow->-r /content/requirements.txt (line 19)) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow->-r /content/requirements.txt (line 19)) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow->-r /content/requirements.txt (line 19)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow->-r /content/requirements.txt (line 19)) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow->-r /content/requirements.txt (line 19)) (3.1.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r /content/requirements.txt (line 7)) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r /content/requirements.txt (line 7)) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r /content/requirements.txt (line 7)) (1.26.1)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27->-r /content/requirements.txt (line 2)) (1.33)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph==0.6.7->-r /content/requirements.txt (line 3))\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph==0.6.7->-r /content/requirements.txt (line 3)) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27->-r /content/requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27->-r /content/requirements.txt (line 2)) (0.25.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow->-r /content/requirements.txt (line 19)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow->-r /content/requirements.txt (line 19)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow->-r /content/requirements.txt (line 19)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow->-r /content/requirements.txt (line 19)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow->-r /content/requirements.txt (line 19)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow->-r /content/requirements.txt (line 19)) (3.2.5)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->-r /content/requirements.txt (line 15)) (2.10.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai==0.3.33->-r /content/requirements.txt (line 4)) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai==0.3.33->-r /content/requirements.txt (line 4)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai==0.3.33->-r /content/requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai==0.3.33->-r /content/requirements.txt (line 4)) (1.3.1)\n",
            "Collecting packaging<26 (from mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow->-r /content/requirements.txt (line 19)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow->-r /content/requirements.txt (line 19)) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27->-r /content/requirements.txt (line 2)) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.33->-r /content/requirements.txt (line 4)) (2024.11.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=2.5->azure-identity->-r /content/requirements.txt (line 15)) (2.23)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (0.17.0)\n",
            "Collecting rich-rst<2.0.0,>=1.3.1 (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading rich_rst-1.3.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (0.48.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (4.0.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r /content/requirements.txt (line 7)) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r /content/requirements.txt (line 7)) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r /content/requirements.txt (line 7)) (1.71.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r /content/requirements.txt (line 7)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r /content/requirements.txt (line 7)) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27->-r /content/requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (4.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (3.0.2)\n",
            "Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (10.8.0)\n",
            "Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading openapi_schema_validator-0.6.3-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading openapi_spec_validator-0.7.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting parse (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting werkzeug>=3.1.0 (from Flask<4->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading werkzeug-3.1.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (0.58b0)\n",
            "Collecting email-validator>=2.0.0 (from pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (2.19.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community==0.3.29->-r /content/requirements.txt (line 5))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow->-r /content/requirements.txt (line 19)) (5.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (0.27.1)\n",
            "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (0.1.2)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (0.1.4)\n",
            "Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19))\n",
            "  Downloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai->-r /content/requirements.txt (line 7)) (0.6.1)\n",
            "Requirement already satisfied: docutils in /usr/local/lib/python3.12/dist-packages (from rich-rst<2.0.0,>=1.3.1->cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow->-r /content/requirements.txt (line 19)) (0.21.2)\n",
            "Downloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.12-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone-7.3.0-py3-none-any.whl (587 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.6/587.6 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_identity-1.25.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_ai_inference-1.0.0b9-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow-3.4.0-py3-none-any.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.4.0-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_tracing-3.4.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.35.1-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastmcp-2.12.4-py3-none-any.whl (329 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.1/329.1 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal-1.34.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
            "Downloading pinecone_plugin_assistant-1.8.0-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.3/259.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Downloading cyclopts-3.24.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.2/86.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.67.0-py3-none-any.whl (718 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.4/718.4 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n",
            "Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openapi_core-0.19.5-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openapi_pydantic-0.5.1-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading werkzeug-3.1.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
            "Downloading jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading openapi_schema_validator-0.6.3-py3-none-any.whl (8.8 kB)\n",
            "Downloading openapi_spec_validator-0.7.2-py3-none-any.whl (39 kB)\n",
            "Downloading rich_rst-1.3.1-py3-none-any.whl (11 kB)\n",
            "Downloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
            "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathable-0.4.4-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: parse, filetype, werkzeug, requests, pinecone-plugin-interface, pathable, packaging, ormsgpack, mypy-extensions, lazy-object-proxy, isodate, graphql-core, exceptiongroup, dnspython, typing-inspect, pydantic, pinecone-plugin-assistant, marshmallow, jsonschema-path, gunicorn, graphql-relay, email-validator, docker, azure-core, rich-rst, pinecone, openapi-pydantic, langgraph-sdk, graphene, dataclasses-json, databricks-sdk, azure-ai-inference, openapi-schema-validator, msal, cyclopts, openapi-spec-validator, msal-extensions, mlflow-tracing, mlflow-skinny, langgraph-checkpoint, langchain-openai, google-ai-generativelanguage, openapi-core, langgraph-prebuilt, langchain_google_genai, azure-identity, langgraph, langchain-community, fastmcp, mlflow\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.9\n",
            "    Uninstalling pydantic-2.11.9:\n",
            "      Successfully uninstalled pydantic-2.11.9\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed azure-ai-inference-1.0.0b9 azure-core-1.35.1 azure-identity-1.25.0 cyclopts-3.24.0 databricks-sdk-0.67.0 dataclasses-json-0.6.7 dnspython-2.8.0 docker-7.1.0 email-validator-2.3.0 exceptiongroup-1.3.0 fastmcp-2.12.4 filetype-1.2.0 google-ai-generativelanguage-0.7.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 isodate-0.7.2 jsonschema-path-0.3.4 langchain-community-0.3.29 langchain-openai-0.3.33 langchain_google_genai-2.1.12 langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.9 lazy-object-proxy-1.12.0 marshmallow-3.26.1 mlflow-3.4.0 mlflow-skinny-3.4.0 mlflow-tracing-3.4.0 msal-1.34.0 msal-extensions-1.3.1 mypy-extensions-1.1.0 openapi-core-0.19.5 openapi-pydantic-0.5.1 openapi-schema-validator-0.6.3 openapi-spec-validator-0.7.2 ormsgpack-1.10.0 packaging-24.2 parse-1.20.2 pathable-0.4.4 pinecone-7.3.0 pinecone-plugin-assistant-1.8.0 pinecone-plugin-interface-0.0.7 pydantic-2.11.7 requests-2.32.5 rich-rst-1.3.1 typing-inspect-0.9.0 werkzeug-3.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "packaging"
                ]
              },
              "id": "fd2f11f1fccc427599d9b7b90c7c7157"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from dotenv import load_dotenv\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv(\"/content/.env\")\n",
        "\n",
        "# --- Configuration ---\n",
        "DATA_FILE = '/content/self_critique_loop_dataset.json'\n",
        "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
        "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
        "AZURE_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
        "embedding_model_name = \"text-embedding-3-small\""
      ],
      "metadata": {
        "id": "0rPN8Lrt1kEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fAkPEGLrzKdV"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# --- Main Indexing Logic ---\n",
        "def setup_and_index():\n",
        "    \"\"\"\n",
        "    Main function to load data, initialize services,\n",
        "    and index the knowledge base into Pinecone.\n",
        "    \"\"\"\n",
        "    print(\"Starting the indexing process...\")\n",
        "\n",
        "    # 1. Initialize Pinecone Client\n",
        "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "    print(\"Pinecone client initialized.\")\n",
        "\n",
        "    # 2. Initialize Azure Embeddings Client\n",
        "    embeddings = AzureOpenAIEmbeddings(\n",
        "        azure_endpoint=os.environ[\"AZURE_OPENAI_EMBEDDING_ENDPOINT\"],\n",
        "        model=embedding_model_name,\n",
        "        azure_deployment=os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\"],\n",
        "        api_key=os.environ[\"AZURE_OPENAI_EMBEDDING_KEY\"],\n",
        "        api_version=os.environ[\"AZURE_OPENAI_EMBEDDING_API_VERSION\"],\n",
        "    )\n",
        "\n",
        "    # AzureOpenAIEmbeddings(\n",
        "    #     azure_deployment=AZURE_DEPLOYMENT,\n",
        "    #     openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
        "    # )\n",
        "    # The dimensions of the text-embedding-3-small model is 1536\n",
        "    embedding_dimension = 1536\n",
        "    print(f\"Azure Embeddings client initialized for model: {AZURE_DEPLOYMENT}\")\n",
        "\n",
        "    # 3. Create Pinecone Index if it doesn't exist\n",
        "    if PINECONE_INDEX_NAME not in pc.list_indexes().names():\n",
        "        print(f\"Creating new serverless index: {PINECONE_INDEX_NAME}\")\n",
        "        pc.create_index(\n",
        "            name=PINECONE_INDEX_NAME,\n",
        "            dimension=embedding_dimension,\n",
        "            metric=\"cosine\",\n",
        "            spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        "        )\n",
        "        print(\"Index created successfully.\")\n",
        "    else:\n",
        "        print(f\"Index '{PINECONE_INDEX_NAME}' already exists. Skipping creation.\")\n",
        "\n",
        "    index = pc.Index(PINECONE_INDEX_NAME)\n",
        "\n",
        "    # 4. Load Knowledge Base Data [cite: 16]\n",
        "    try:\n",
        "        with open(DATA_FILE, 'r') as f:\n",
        "            kb_data = json.load(f)\n",
        "        print(f\"Successfully loaded {len(kb_data)} entries from {DATA_FILE}.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The data file '{DATA_FILE}' was not found.\")\n",
        "        return\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Could not decode JSON from the file '{DATA_FILE}'.\")\n",
        "        return\n",
        "\n",
        "    # 5. Generate Embeddings and Upsert to Pinecone\n",
        "    print(\"Generating embeddings and upserting data to Pinecone...\")\n",
        "    batch_size = 100\n",
        "    vectors_to_upsert = []\n",
        "\n",
        "    for doc in tqdm(kb_data, desc=\"Processing documents\"):\n",
        "        # The vector is created from the 'answer_snippet'\n",
        "        vector = embeddings.embed_query(doc['question'])\n",
        "\n",
        "        # Metadata includes the original content and source info\n",
        "        metadata = {\n",
        "            'question': doc['question'],\n",
        "            'answer_snippet': doc['answer_snippet'],\n",
        "            'source': doc['source'],\n",
        "            'confidence_indicator': doc['confidence_indicator'],\n",
        "            'last_updated': doc['last_updated']\n",
        "        }\n",
        "\n",
        "        vectors_to_upsert.append({\n",
        "            'id': doc['doc_id'], # Use doc_id as the unique identifier\n",
        "            'values': vector,\n",
        "            'metadata': metadata\n",
        "        })\n",
        "\n",
        "        # Upsert in batches\n",
        "        if len(vectors_to_upsert) >= batch_size:\n",
        "            index.upsert(vectors=vectors_to_upsert)\n",
        "            vectors_to_upsert = []\n",
        "\n",
        "    # Upsert any remaining vectors\n",
        "    if vectors_to_upsert:\n",
        "        index.upsert(vectors=vectors_to_upsert)\n",
        "\n",
        "    print(\"\\nIndexing complete!\")\n",
        "    print(f\"Final index stats: {index.describe_index_stats()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "setup_and_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKGv75or0Xue",
        "outputId": "b326d690-0c77-4fe6-df35-bebfd4708d01"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting the indexing process...\n",
            "Pinecone client initialized.\n",
            "Azure Embeddings client initialized for model: None\n",
            "Index 'agentic-rag-index' already exists. Skipping creation.\n",
            "Successfully loaded 30 entries from self_critique_loop_dataset.json.\n",
            "Generating embeddings and upserting data to Pinecone...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing documents: 100%|██████████| 30/30 [00:07<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Indexing complete!\n",
            "Final index stats: {'dimension': 1536,\n",
            " 'index_fullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {'': {'vector_count': 30}},\n",
            " 'total_vector_count': 30,\n",
            " 'vector_type': 'dense'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agentic Framework"
      ],
      "metadata": {
        "id": "dRxuppeb0_Pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import uuid\n",
        "from typing import List, Dict, TypedDict\n",
        "\n",
        "import mlflow\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.pydantic_v1 import BaseModel\n",
        "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from pinecone import Pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dry4u__L1Ho-",
        "outputId": "afab33ce-1272-429a-92ee-98bceac86ea2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model and Service Initialization ---\n",
        "AZURE_EMBEDDING_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
        "AZURE_GENERATION_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_GPT4_MINI_DEPLOYMENT\")\n",
        "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
        "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "\n",
        "# Initialize clients\n",
        "embeddings = AzureOpenAIEmbeddings(\n",
        "    azure_endpoint=os.environ[\"AZURE_OPENAI_EMBEDDING_ENDPOINT\"],\n",
        "    model=embedding_model_name,\n",
        "    azure_deployment=os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\"],\n",
        "    api_key=os.environ[\"AZURE_OPENAI_EMBEDDING_KEY\"],\n",
        "    api_version=os.environ[\"AZURE_OPENAI_EMBEDDING_API_VERSION\"],\n",
        ")\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "index = pc.Index(PINECONE_INDEX_NAME)\n",
        "\n",
        "# LLM for generation\n",
        "generator_llm = AzureChatOpenAI(\n",
        "    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
        "    openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
        "    openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
        "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "    openai_api_type=os.getenv(\"OPENAI_API_TYPE\"),\n",
        "    temperature=0.2,\n",
        "    # streaming=False,\n",
        ")\n",
        "\n",
        "# LLM for self-critique\n",
        "critique_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)"
      ],
      "metadata": {
        "id": "daZZb-Fn1bGD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- State Definition for the Graph ---\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "    \"\"\"\n",
        "    question: str\n",
        "    generation: str\n",
        "    documents: List[Dict]\n",
        "    critique: str\n",
        "    run_id: str\n"
      ],
      "metadata": {
        "id": "L4suwrSt2BUx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Node Definitions ---\n",
        "\n",
        "def retrieve(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    Retrieves documents from the vector database.\n",
        "    [cite: 20]\n",
        "    \"\"\"\n",
        "    print(\"---NODE: RETRIEVE---\")\n",
        "    question = state[\"question\"]\n",
        "    question_embedding = embeddings.embed_query(question)\n",
        "\n",
        "    # Retrieve top-5 snippets [cite: 20]\n",
        "    retrieval_results = index.query(vector=question_embedding, top_k=5, include_metadata=True)\n",
        "    documents = [\n",
        "        {\"doc_id\": match['id'], **match['metadata']}\n",
        "        for match in retrieval_results['matches']\n",
        "    ]\n",
        "\n",
        "    print(f\"Retrieved {len(documents)} documents.\")\n",
        "    mlflow.log_dict({\"initial_retrieval\": documents}, \"retrieval_results.json\")\n",
        "    return {\"documents\": documents, **state}\n",
        "\n",
        "def generate(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    Generates a list of the most relevant source documents using an LLM.\n",
        "    The LLM acts as a relevance filter on the retrieved documents.\n",
        "    \"\"\"\n",
        "    print(\"---NODE: GENERATE---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Create a detailed context string for the LLM to analyze.\n",
        "    # Each document's content and source information are clearly presented.\n",
        "    context_for_llm = \"\\n\\n\".join(\n",
        "        f\"Document ID: {doc['doc_id']}\\nSource: {doc['source']}\\nContent: {doc['answer_snippet']}\"\n",
        "        for doc in documents\n",
        "    )\n",
        "\n",
        "    # The new prompt instructs the LLM to select and format, not to answer.\n",
        "    prompt = f\"\"\"You are an AI assistant that helps users find the most relevant knowledge base documents.\n",
        "Your task is to review the user's question and the list of retrieved documents below. From this list, identify and list ONLY the most relevant documents the user should read.\n",
        "\n",
        "Your response MUST be a list of the source file names, their content and their corresponding document IDs. Format each entry on a new line like this: `source_file.md [DOC_ID]: content `.\n",
        "Do not add any other text, explanation, or conversational filler.\n",
        "\n",
        "User's Question: \"{question}\"\n",
        "\n",
        "Retrieved Documents:\n",
        "{context_for_llm}\n",
        "\n",
        "Relevant Sources:\n",
        "\"\"\"\n",
        "\n",
        "    # Re-introduce the LLM call with the new prompt\n",
        "    generation = generator_llm.invoke(prompt).content\n",
        "    print(f\"Generated Source List:\\n{generation}\")\n",
        "\n",
        "    # Log the output\n",
        "    if state.get('critique'): # Check if this is the refinement stage\n",
        "         mlflow.log_text(generation, \"refined_answer.txt\")\n",
        "    else:\n",
        "         mlflow.log_text(generation, \"generated_answer.txt\")\n",
        "\n",
        "    return {\"generation\": generation, **state}\n",
        "\n",
        "def grade_generation(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    Critiques the LLM-generated list of source documents, using the full\n",
        "    retrieved context for an accurate evaluation.\n",
        "    \"\"\"\n",
        "    print(\"---NODE: SELF-CRITIQUE---\")\n",
        "    question = state[\"question\"]\n",
        "    # documents = state[\"documents\"]\n",
        "    generation = state[\"generation\"] # The list of sources from the generate node\n",
        "\n",
        "    # Full knowledge db\n",
        "    with open(DATA_FILE, 'r') as f:\n",
        "      documents = json.load(f)\n",
        "\n",
        "    # **This is the corrected part**\n",
        "    # Now builds a detailed context of the full pool of documents,\n",
        "    # matching the context given to the generator node.\n",
        "    full_context = \"\\n\\n\".join(\n",
        "        f\"Document ID: {doc['doc_id']}\\nSource: {doc['source']}\\nContent: {doc['answer_snippet']}\"\n",
        "        for doc in documents\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"You are a grader. An AI assistant was given a user's question and a pool of retrieved documents. The assistant then selected a subset of those documents as a final recommendation.\n",
        "\n",
        "Your task is to evaluate if this final recommendation is sufficient and relevant based on the full context provided.\n",
        "- If the recommended list accurately and sufficiently addresses the user's question, respond 'COMPLETE'.\n",
        "- If the list is missing key documents from the available pool or seems irrelevant, respond 'REFINE'.\n",
        "\n",
        "User's Question: \"{question}\"\n",
        "\n",
        "Full Pool of Retrieved Documents:\n",
        "{full_context}\n",
        "\n",
        "AI's Recommended List:\n",
        "{generation}\n",
        "\n",
        "Decision (COMPLETE or REFINE):\n",
        "\"\"\"\n",
        "\n",
        "    critique = critique_llm.invoke(prompt).content.strip().upper()\n",
        "    print(f\"Critique Result: {critique}\")\n",
        "    mlflow.log_param(\"critique_result\", critique)\n",
        "    return {\"critique\": critique, **state}\n",
        "\n",
        "def refine(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    Retrieves one additional document and regenerates the answer.\n",
        "    [cite: 25]\n",
        "    \"\"\"\n",
        "    print(\"---NODE: REFINE---\")\n",
        "    question = state[\"question\"]\n",
        "    existing_doc_ids = [doc['doc_id'] for doc in state['documents']]\n",
        "\n",
        "    question_embedding = embeddings.embed_query(question)\n",
        "\n",
        "    # Retrieve 6 documents to get one new one\n",
        "    retrieval_results = index.query(\n",
        "        vector=question_embedding,\n",
        "        top_k=6,\n",
        "        include_metadata=True\n",
        "    )\n",
        "\n",
        "    new_documents = state['documents']\n",
        "    for match in retrieval_results['matches']:\n",
        "        if match['id'] not in existing_doc_ids:\n",
        "            new_doc = {\"doc_id\": match['id'], **match['metadata']}\n",
        "            new_documents.append(new_doc)\n",
        "            print(f\"Refinement: Added new document {match['id']}\")\n",
        "            mlflow.log_dict({\"refinement_doc\": new_doc}, \"refinement_doc.json\")\n",
        "            break\n",
        "\n",
        "    # Update state with new docs and re-generate\n",
        "    new_state = {\"documents\": new_documents, **state}\n",
        "    refined_state = generate(new_state)\n",
        "\n",
        "    mlflow.log_text(refined_state['generation'], \"refined_answer.txt\")\n",
        "    return refined_state"
      ],
      "metadata": {
        "id": "5h48800u2CPi"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Conditional Edge Logic ---\n",
        "\n",
        "def decide_to_finish(state: GraphState) -> str:\n",
        "    \"\"\"\n",
        "    Determines the next step based on the critique.\n",
        "    [cite: 26]\n",
        "    \"\"\"\n",
        "    print(\"---EDGE: DECISION---\")\n",
        "    if state[\"critique\"] == \"COMPLETE\":\n",
        "        print(\"Decision: COMPLETE. Ending workflow.\")\n",
        "        return \"end\"\n",
        "    else:\n",
        "        print(\"Decision: REFINE. Proceeding to refinement.\")\n",
        "        return \"refine\"\n",
        "\n",
        "# --- Build the Graph ---\n",
        "\n",
        "def build_graph():\n",
        "    \"\"\"Builds and compiles the LangGraph workflow.\"\"\"\n",
        "    workflow = StateGraph(GraphState)\n",
        "\n",
        "    # Add nodes\n",
        "    workflow.add_node(\"retrieve\", retrieve)\n",
        "    workflow.add_node(\"generate\", generate)\n",
        "    workflow.add_node(\"grade_generation\", grade_generation)\n",
        "    workflow.add_node(\"refine\", refine)\n",
        "\n",
        "    # Set entry point\n",
        "    workflow.set_entry_point(\"retrieve\")\n",
        "\n",
        "    # Add edges\n",
        "    workflow.add_edge(\"retrieve\", \"generate\")\n",
        "    workflow.add_edge(\"generate\", \"grade_generation\")\n",
        "    workflow.add_conditional_edges(\n",
        "        \"grade_generation\",\n",
        "        decide_to_finish,\n",
        "        {\"refine\": \"refine\", \"end\": END},\n",
        "    )\n",
        "    workflow.add_edge(\"refine\", END) # Max 1 refinement step [cite: 60]\n",
        "\n",
        "    return workflow.compile()"
      ],
      "metadata": {
        "id": "aJoXwYu12I9L"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main Execution ---\n",
        "\n",
        "def run_agentic_rag(query: str):\n",
        "    \"\"\"\n",
        "    Executes the full RAG pipeline for a given query and logs with MLflow.\n",
        "    \"\"\"\n",
        "    mlflow.set_experiment(\"Agentic RAG System\")\n",
        "\n",
        "    with mlflow.start_run() as run:\n",
        "        run_id = run.info.run_id\n",
        "        print(f\"Starting MLflow Run ID: {run_id}\")\n",
        "        mlflow.log_param(\"user_query\", query)\n",
        "\n",
        "        app = build_graph()\n",
        "\n",
        "        inputs = {\"question\": query, \"run_id\": run_id}\n",
        "        final_state = app.invoke(inputs)\n",
        "\n",
        "        final_answer = final_state[\"generation\"]\n",
        "        print(\"\\n--- FINAL ANSWER ---\")\n",
        "        print(final_answer)\n",
        "\n",
        "        mlflow.log_text(final_answer, \"final_answer.txt\")\n",
        "        mlflow.log_dict(final_state, \"final_state.json\")\n",
        "        print(f\"\\n--- MLflow logging complete. View run at http://127.0.0.1:8080 ---\")"
      ],
      "metadata": {
        "id": "vfAIw2dR2NUa"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample queries from the assignment\n",
        "sample_query = \"What are best practices for caching?\"\n",
        "# sample_query = \"How should I set up CI/CD pipelines?\"\n",
        "# sample_query = \"What are performance tuning tips?\"\n",
        "# sample_query = \"How do I version my APIs?\"\n",
        "# sample_query = \"What should I consider for error handling?\"\n",
        "\n",
        "run_agentic_rag(sample_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhycnqBg2Poa",
        "outputId": "c49c0260-9a63-498a-e351-5d7dfa509077"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting MLflow Run ID: 670991b7b29b42afab580a9a04290409\n",
            "---NODE: RETRIEVE---\n",
            "Retrieved 5 documents.\n",
            "---NODE: GENERATE---\n",
            "Generated Source List:\n",
            "caching_guide.md [KB003]: When addressing caching, it's important to follow well-defined patterns...  \n",
            "caching_guide.md [KB023]: When addressing caching, it's important to follow well-defined patterns...  \n",
            "caching_guide.md [KB013]: When addressing caching, it's important to follow well-defined patterns...  \n",
            "---NODE: SELF-CRITIQUE---\n",
            "Critique Result: COMPLETE\n",
            "---EDGE: DECISION---\n",
            "Decision: COMPLETE. Ending workflow.\n",
            "\n",
            "--- FINAL ANSWER ---\n",
            "caching_guide.md [KB003]: When addressing caching, it's important to follow well-defined patterns...  \n",
            "caching_guide.md [KB023]: When addressing caching, it's important to follow well-defined patterns...  \n",
            "caching_guide.md [KB013]: When addressing caching, it's important to follow well-defined patterns...  \n",
            "\n",
            "--- MLflow logging complete. View run at http://127.0.0.1:8080 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u1NV9Ut_2STN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}